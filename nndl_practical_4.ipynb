{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyNMbckFGxDxEICdZ8JLtDZ3",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/SunnyDahitJ/NNDL/blob/main/nndl_practical_4.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IBY1ctRgxF56",
        "outputId": "9e156526-44d4-4048-d342-b95f8868e658"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "input labels: \n",
            "[[ 1  1]\n",
            " [ 1 -1]\n",
            " [-1  1]\n",
            " [-1 -1]]\n",
            "\n",
            "output labels: \n",
            "[ 1  1  1 -1]\n"
          ]
        }
      ],
      "source": [
        "# import the module numpy\n",
        "import numpy as np\n",
        "\n",
        "\n",
        "# the features for the or model , here we have\n",
        "# taken the possible values for combination of\n",
        "# two inputs\n",
        "features = np.array(\n",
        "\t[\n",
        "\t\t[1, 1],\n",
        "\t\t[1, -1],\n",
        "\t\t[-1, 1],\n",
        "\t\t[-1, -1]\n",
        "\t])\n",
        "\n",
        "\n",
        "# labels for the or model, here the output for\n",
        "# the features is taken as an array\n",
        "labels = np.array([1, 1, 1, -1])\n",
        "\n",
        "# to print the features and the labels for\n",
        "# which the model has to be trained\n",
        "print(f\"input labels: \\n{features}\\n\\noutput labels: \\n{labels}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# initialise weights, bias , learning rate, epoch\n",
        "weight = [0.1, 0.1]\n",
        "bias = 0.1\n",
        "learning_rate = 0.1\n",
        "epoch = 10\n",
        "\n",
        "for i in range(epoch):\n",
        "\n",
        "\t# epoch is the number of the model is trained\n",
        "\t# with the same data\n",
        "\tprint(\"epoch :\", i+1)\n",
        "\n",
        "\t# variable to check if there is no change in previous\n",
        "\t# weight and present calculated weight\n",
        "\t# initial error is kept as 0\n",
        "\tsum_squared_error = 0.0\n",
        "\n",
        "\t# for each of the possible input given in the features\n",
        "\tfor j in range(features.shape[0]):\n",
        "\n",
        "\t\t# actual output to be obtained\n",
        "\t\tactual = labels[j]\n",
        "\n",
        "\t\t# the value of two features as given in the features\n",
        "\t\t# array\n",
        "\t\tx1 = features[j][0]\n",
        "\t\tx2 = features[j][1]\n",
        "    \n",
        "\t\t# net unit value computation performed to obtain the\n",
        "\t\t# sum of features multiplied with their weights\n",
        "\t\tunit = (x1 * weight[0]) + (x2 * weight[1]) + bias\n",
        "\n",
        "\t\t# error is computed so as to update the weights\n",
        "\t\terror = actual - unit\n",
        "\n",
        "\t\t# print statement to print the actual value , predicted\n",
        "\t\t# value and the error\n",
        "\t\tprint(\"error =\", error)\n",
        "\n",
        "\t\t# summation of squared error is calculated\n",
        "\t\tsum_squared_error += error * error\n",
        "\n",
        "\t\t# updation of weights, summing up of product of learning rate ,\n",
        "\t\t# sum of squared error and feature value\n",
        "\t\tweight[0] += learning_rate * error * x1\n",
        "\t\tweight[1] += learning_rate * error * x2\n",
        "\n",
        "\t\t# updation of bias, summing up of product of learning rate and\n",
        "\t\t# sum of squared error\n",
        "\t\tbias += learning_rate * error\n",
        "\n",
        "\tprint(\"sum of squared error = \", sum_squared_error/4, \"\\n\\n\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 130
        },
        "id": "uWx68ecH0Ig-",
        "outputId": "27824584-293c-4121-8725-c2ce1499a5fb"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "IndentationError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;36m  File \u001b[0;32m\"<tokenize>\"\u001b[0;36m, line \u001b[0;32m29\u001b[0m\n\u001b[0;31m    print(x1,x2)\u001b[0m\n\u001b[0m    ^\u001b[0m\n\u001b[0;31mIndentationError\u001b[0m\u001b[0;31m:\u001b[0m unindent does not match any outer indentation level\n"
          ]
        }
      ]
    }
  ]
}