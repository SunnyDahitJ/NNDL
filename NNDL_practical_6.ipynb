{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyOMiDJKExyqyToPYQudr1LT",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/SunnyDahitJ/NNDL/blob/main/NNDL_practical_6.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ffzBSYw3qVcl"
      },
      "outputs": [],
      "source": [
        "from math import exp\n",
        "from random import seed\n",
        "from random import random\n",
        "import pandas as pd\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.svm import SVC\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class BPN:\n",
        "  def __init__(self, train_data, test_data, n_hidden, l_rate, n_epochs):\n",
        "    self.train_data = train_data\n",
        "    self.test_data = test_data\n",
        "    self.n_hidden = n_hidden\n",
        "    self.l_rate = l_rate\n",
        "    self.n_epochs = n_epochs\n",
        "    self.network = list()\n",
        "\n",
        "  # Initialize a network\n",
        "  def initialize_network(self):\n",
        "    n_inputs = len(self.train_data[0]) - 1\n",
        "    n_outputs = len(set([row[-1] for row in self.train_data]))\n",
        "\n",
        "    hidden_layer = [{'weights':[random() for i in range(n_inputs + 1)]} for i in range(self.n_hidden)]\n",
        "    self.network.append(hidden_layer)\n",
        "    output_layer = [{'weights':[random() for i in range(self.n_hidden + 1)]} for i in range(n_outputs)]\n",
        "    self.network.append(output_layer)\n",
        "\n",
        "  def activate(self, weights, inputs):\n",
        "    activation = weights[-1]\n",
        "\n",
        "    for i in range(len(weights)-1):\n",
        "      activation += weights[i] * inputs[i]\n",
        "    return activation\n",
        "\n",
        "  def transfer(self, activation):\n",
        "    return 1.0 / (1.0 + exp(-activation))\n",
        "\n",
        "  def forward_propagate(self, row):\n",
        "    inputs = row\n",
        "    for layer in self.network:\n",
        "      new_inputs = []\n",
        "      for neuron in layer:\n",
        "        activation = self.activate(neuron['weights'], inputs)\n",
        "        neuron['output'] = self.transfer(activation)\n",
        "        new_inputs.append(neuron['output'])\n",
        "      inputs = new_inputs\n",
        "    return inputs\n",
        "\n",
        "  def transfer_derivative(self, output):\n",
        "    return output * (1.0 - output)\n",
        "\n",
        "  def backward_propagate_error(self, expected):\n",
        "    for i in reversed(range(len(self.network))):\n",
        "      layer = self.network[i]\n",
        "      errors = list()\n",
        "      if i != len(self.network)-1:\n",
        "        for j in range(len(layer)):\n",
        "          error = 0.0\n",
        "          for neuron in self.network[i + 1]:\n",
        "            error += (neuron['weights'][j] * neuron['delta'])\n",
        "          errors.append(error)\n",
        "      else:\n",
        "        for j in range(len(layer)):\n",
        "          neuron = layer[j]\n",
        "          errors.append(neuron['output'] - expected[j])\n",
        "      for j in range(len(layer)):\n",
        "        neuron = layer[j]\n",
        "        neuron['delta'] = errors[j] * self.transfer_derivative(neuron['output'])\n",
        "\n",
        "  def update_weights(self, row):\n",
        "    for i in range(len(self.network)):\n",
        "      inputs = row[:-1]\n",
        "      if i != 0:\n",
        "        inputs = [neuron['output'] for neuron in self.network[i - 1]]\n",
        "      for neuron in self.network[i]:\n",
        "        for j in range(len(inputs)):\n",
        "          neuron['weights'][j] -= self.l_rate * neuron['delta'] * inputs[j]\n",
        "        neuron['weights'][-1] -= self.l_rate * neuron['delta']\n",
        "\n",
        "  def train_network(self):\n",
        "    self.initialize_network()\n",
        "    n_outputs = len(set([row[-1] for row in self.train_data]))\n",
        "    # print(n_outputs)\n",
        "\n",
        "    for epoch in range(self.n_epochs):\n",
        "      sum_error = 0\n",
        "      for row in self.train_data:\n",
        "        outputs = self.forward_propagate(row)\n",
        "        expected = [0 for i in range(n_outputs)]\n",
        "        expected[int(row[-1])] = 1\n",
        "        sum_error += sum([(expected[i] - outputs[i]) ** 2 for i in range(len(expected))])\n",
        "        self.backward_propagate_error(expected)\n",
        "        self.update_weights(row)\n",
        "      print('>epoch=%d, lrate=%.3f, MSE=%f' % (epoch + 1, self.l_rate, sum_error / len(self.train_data)))\n",
        "\n",
        "  def predict(self, row):\n",
        "    outputs = self.forward_propagate(row)\n",
        "    return outputs.index(max(outputs))\n",
        "  \n",
        "  def show_predictions(self):\n",
        "    self.y_pred = []\n",
        "    for row in self.test_data:\n",
        "      prediction = self.predict(row)\n",
        "      self.y_pred.append(prediction)\n",
        "      prefix = '+' if row[-1] == prediction else '-'\n",
        "      print('%s Expected=%d, Got=%d' % (prefix, row[-1], prediction))\n",
        "  \n",
        "  def get_accuracy_score(self):\n",
        "    score = 0\n",
        "    self.y_pred = []\n",
        "    for row in self.test_data:\n",
        "      prediction = self.predict(row)\n",
        "      self.y_pred.append(prediction)\n",
        "      score += 1 if row[-1] == prediction else 0\n",
        "    return (score / len(test)) * 100\n",
        "    # print(f\"Accuracy score: { ((score / len(test)) * 100) }\")"
      ],
      "metadata": {
        "id": "x3UFxzzjqdTJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df = pd.read_csv(\"iris_dataset.csv\")\n",
        "df.Species = pd.Series(LabelEncoder().fit_transform(df.Species))\n",
        "df_array = df.iloc[:, 1:].to_numpy()\n",
        "df_array"
      ],
      "metadata": {
        "id": "r6zTG1pGuJ6O"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "seed(1)\n",
        "df = pd.read_csv(\"iris_dataset.csv\")\n",
        "df.Species = pd.Series(LabelEncoder().fit_transform(df.Species))\n",
        "df_array = df.iloc[:, 1:].to_numpy()\n",
        "df_array"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lDzkCZfQqdd_",
        "outputId": "914a63d6-454b-466a-d3a3-57b148e1d7e4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[5.1, 3.5, 1.4, 0.2, 0. ],\n",
              "       [4.9, 3. , 1.4, 0.2, 0. ],\n",
              "       [4.7, 3.2, 1.3, 0.2, 0. ],\n",
              "       [4.6, 3.1, 1.5, 0.2, 0. ],\n",
              "       [5. , 3.6, 1.4, 0.2, 0. ],\n",
              "       [5.4, 3.9, 1.7, 0.4, 0. ],\n",
              "       [4.6, 3.4, 1.4, 0.3, 0. ],\n",
              "       [5. , 3.4, 1.5, 0.2, 0. ],\n",
              "       [4.4, 2.9, 1.4, 0.2, 0. ],\n",
              "       [4.9, 3.1, 1.5, 0.1, 0. ],\n",
              "       [5.4, 3.7, 1.5, 0.2, 0. ],\n",
              "       [4.8, 3.4, 1.6, 0.2, 0. ],\n",
              "       [4.8, 3. , 1.4, 0.1, 0. ],\n",
              "       [4.3, 3. , 1.1, 0.1, 0. ],\n",
              "       [5.8, 4. , 1.2, 0.2, 0. ],\n",
              "       [5.7, 4.4, 1.5, 0.4, 0. ],\n",
              "       [5.4, 3.9, 1.3, 0.4, 0. ],\n",
              "       [5.1, 3.5, 1.4, 0.3, 0. ],\n",
              "       [5.7, 3.8, 1.7, 0.3, 0. ],\n",
              "       [5.1, 3.8, 1.5, 0.3, 0. ],\n",
              "       [5.4, 3.4, 1.7, 0.2, 0. ],\n",
              "       [5.1, 3.7, 1.5, 0.4, 0. ],\n",
              "       [4.6, 3.6, 1. , 0.2, 0. ],\n",
              "       [5.1, 3.3, 1.7, 0.5, 0. ],\n",
              "       [4.8, 3.4, 1.9, 0.2, 0. ],\n",
              "       [5. , 3. , 1.6, 0.2, 0. ],\n",
              "       [5. , 3.4, 1.6, 0.4, 0. ],\n",
              "       [5.2, 3.5, 1.5, 0.2, 0. ],\n",
              "       [5.2, 3.4, 1.4, 0.2, 0. ],\n",
              "       [4.7, 3.2, 1.6, 0.2, 0. ],\n",
              "       [4.8, 3.1, 1.6, 0.2, 0. ],\n",
              "       [5.4, 3.4, 1.5, 0.4, 0. ],\n",
              "       [5.2, 4.1, 1.5, 0.1, 0. ],\n",
              "       [5.5, 4.2, 1.4, 0.2, 0. ],\n",
              "       [4.9, 3.1, 1.5, 0.1, 0. ],\n",
              "       [5. , 3.2, 1.2, 0.2, 0. ],\n",
              "       [5.5, 3.5, 1.3, 0.2, 0. ],\n",
              "       [4.9, 3.1, 1.5, 0.1, 0. ],\n",
              "       [4.4, 3. , 1.3, 0.2, 0. ],\n",
              "       [5.1, 3.4, 1.5, 0.2, 0. ],\n",
              "       [5. , 3.5, 1.3, 0.3, 0. ],\n",
              "       [4.5, 2.3, 1.3, 0.3, 0. ],\n",
              "       [4.4, 3.2, 1.3, 0.2, 0. ],\n",
              "       [5. , 3.5, 1.6, 0.6, 0. ],\n",
              "       [5.1, 3.8, 1.9, 0.4, 0. ],\n",
              "       [4.8, 3. , 1.4, 0.3, 0. ],\n",
              "       [5.1, 3.8, 1.6, 0.2, 0. ],\n",
              "       [4.6, 3.2, 1.4, 0.2, 0. ],\n",
              "       [5.3, 3.7, 1.5, 0.2, 0. ],\n",
              "       [5. , 3.3, 1.4, 0.2, 0. ],\n",
              "       [7. , 3.2, 4.7, 1.4, 1. ],\n",
              "       [6.4, 3.2, 4.5, 1.5, 1. ],\n",
              "       [6.9, 3.1, 4.9, 1.5, 1. ],\n",
              "       [5.5, 2.3, 4. , 1.3, 1. ],\n",
              "       [6.5, 2.8, 4.6, 1.5, 1. ],\n",
              "       [5.7, 2.8, 4.5, 1.3, 1. ],\n",
              "       [6.3, 3.3, 4.7, 1.6, 1. ],\n",
              "       [4.9, 2.4, 3.3, 1. , 1. ],\n",
              "       [6.6, 2.9, 4.6, 1.3, 1. ],\n",
              "       [5.2, 2.7, 3.9, 1.4, 1. ],\n",
              "       [5. , 2. , 3.5, 1. , 1. ],\n",
              "       [5.9, 3. , 4.2, 1.5, 1. ],\n",
              "       [6. , 2.2, 4. , 1. , 1. ],\n",
              "       [6.1, 2.9, 4.7, 1.4, 1. ],\n",
              "       [5.6, 2.9, 3.6, 1.3, 1. ],\n",
              "       [6.7, 3.1, 4.4, 1.4, 1. ],\n",
              "       [5.6, 3. , 4.5, 1.5, 1. ],\n",
              "       [5.8, 2.7, 4.1, 1. , 1. ],\n",
              "       [6.2, 2.2, 4.5, 1.5, 1. ],\n",
              "       [5.6, 2.5, 3.9, 1.1, 1. ],\n",
              "       [5.9, 3.2, 4.8, 1.8, 1. ],\n",
              "       [6.1, 2.8, 4. , 1.3, 1. ],\n",
              "       [6.3, 2.5, 4.9, 1.5, 1. ],\n",
              "       [6.1, 2.8, 4.7, 1.2, 1. ],\n",
              "       [6.4, 2.9, 4.3, 1.3, 1. ],\n",
              "       [6.6, 3. , 4.4, 1.4, 1. ],\n",
              "       [6.8, 2.8, 4.8, 1.4, 1. ],\n",
              "       [6.7, 3. , 5. , 1.7, 1. ],\n",
              "       [6. , 2.9, 4.5, 1.5, 1. ],\n",
              "       [5.7, 2.6, 3.5, 1. , 1. ],\n",
              "       [5.5, 2.4, 3.8, 1.1, 1. ],\n",
              "       [5.5, 2.4, 3.7, 1. , 1. ],\n",
              "       [5.8, 2.7, 3.9, 1.2, 1. ],\n",
              "       [6. , 2.7, 5.1, 1.6, 1. ],\n",
              "       [5.4, 3. , 4.5, 1.5, 1. ],\n",
              "       [6. , 3.4, 4.5, 1.6, 1. ],\n",
              "       [6.7, 3.1, 4.7, 1.5, 1. ],\n",
              "       [6.3, 2.3, 4.4, 1.3, 1. ],\n",
              "       [5.6, 3. , 4.1, 1.3, 1. ],\n",
              "       [5.5, 2.5, 4. , 1.3, 1. ],\n",
              "       [5.5, 2.6, 4.4, 1.2, 1. ],\n",
              "       [6.1, 3. , 4.6, 1.4, 1. ],\n",
              "       [5.8, 2.6, 4. , 1.2, 1. ],\n",
              "       [5. , 2.3, 3.3, 1. , 1. ],\n",
              "       [5.6, 2.7, 4.2, 1.3, 1. ],\n",
              "       [5.7, 3. , 4.2, 1.2, 1. ],\n",
              "       [5.7, 2.9, 4.2, 1.3, 1. ],\n",
              "       [6.2, 2.9, 4.3, 1.3, 1. ],\n",
              "       [5.1, 2.5, 3. , 1.1, 1. ],\n",
              "       [5.7, 2.8, 4.1, 1.3, 1. ],\n",
              "       [6.3, 3.3, 6. , 2.5, 2. ],\n",
              "       [5.8, 2.7, 5.1, 1.9, 2. ],\n",
              "       [7.1, 3. , 5.9, 2.1, 2. ],\n",
              "       [6.3, 2.9, 5.6, 1.8, 2. ],\n",
              "       [6.5, 3. , 5.8, 2.2, 2. ],\n",
              "       [7.6, 3. , 6.6, 2.1, 2. ],\n",
              "       [4.9, 2.5, 4.5, 1.7, 2. ],\n",
              "       [7.3, 2.9, 6.3, 1.8, 2. ],\n",
              "       [6.7, 2.5, 5.8, 1.8, 2. ],\n",
              "       [7.2, 3.6, 6.1, 2.5, 2. ],\n",
              "       [6.5, 3.2, 5.1, 2. , 2. ],\n",
              "       [6.4, 2.7, 5.3, 1.9, 2. ],\n",
              "       [6.8, 3. , 5.5, 2.1, 2. ],\n",
              "       [5.7, 2.5, 5. , 2. , 2. ],\n",
              "       [5.8, 2.8, 5.1, 2.4, 2. ],\n",
              "       [6.4, 3.2, 5.3, 2.3, 2. ],\n",
              "       [6.5, 3. , 5.5, 1.8, 2. ],\n",
              "       [7.7, 3.8, 6.7, 2.2, 2. ],\n",
              "       [7.7, 2.6, 6.9, 2.3, 2. ],\n",
              "       [6. , 2.2, 5. , 1.5, 2. ],\n",
              "       [6.9, 3.2, 5.7, 2.3, 2. ],\n",
              "       [5.6, 2.8, 4.9, 2. , 2. ],\n",
              "       [7.7, 2.8, 6.7, 2. , 2. ],\n",
              "       [6.3, 2.7, 4.9, 1.8, 2. ],\n",
              "       [6.7, 3.3, 5.7, 2.1, 2. ],\n",
              "       [7.2, 3.2, 6. , 1.8, 2. ],\n",
              "       [6.2, 2.8, 4.8, 1.8, 2. ],\n",
              "       [6.1, 3. , 4.9, 1.8, 2. ],\n",
              "       [6.4, 2.8, 5.6, 2.1, 2. ],\n",
              "       [7.2, 3. , 5.8, 1.6, 2. ],\n",
              "       [7.4, 2.8, 6.1, 1.9, 2. ],\n",
              "       [7.9, 3.8, 6.4, 2. , 2. ],\n",
              "       [6.4, 2.8, 5.6, 2.2, 2. ],\n",
              "       [6.3, 2.8, 5.1, 1.5, 2. ],\n",
              "       [6.1, 2.6, 5.6, 1.4, 2. ],\n",
              "       [7.7, 3. , 6.1, 2.3, 2. ],\n",
              "       [6.3, 3.4, 5.6, 2.4, 2. ],\n",
              "       [6.4, 3.1, 5.5, 1.8, 2. ],\n",
              "       [6. , 3. , 4.8, 1.8, 2. ],\n",
              "       [6.9, 3.1, 5.4, 2.1, 2. ],\n",
              "       [6.7, 3.1, 5.6, 2.4, 2. ],\n",
              "       [6.9, 3.1, 5.1, 2.3, 2. ],\n",
              "       [5.8, 2.7, 5.1, 1.9, 2. ],\n",
              "       [6.8, 3.2, 5.9, 2.3, 2. ],\n",
              "       [6.7, 3.3, 5.7, 2.5, 2. ],\n",
              "       [6.7, 3. , 5.2, 2.3, 2. ],\n",
              "       [6.3, 2.5, 5. , 1.9, 2. ],\n",
              "       [6.5, 3. , 5.2, 2. , 2. ],\n",
              "       [6.2, 3.4, 5.4, 2.3, 2. ],\n",
              "       [5.9, 3. , 5.1, 1.8, 2. ]])"
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "SayyI9VLuH1j"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "np.random.shuffle(df_array)\n",
        "print(df_array)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UlQh-TIPqdo0",
        "outputId": "5eb63cf9-82b0-4c5a-ccc9-28b39e47911e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[6.3 2.5 4.9 1.5 1. ]\n",
            " [5.8 2.7 3.9 1.2 1. ]\n",
            " [5.7 3.8 1.7 0.3 0. ]\n",
            " [6.5 2.8 4.6 1.5 1. ]\n",
            " [6.8 3.2 5.9 2.3 2. ]\n",
            " [6.7 3.3 5.7 2.1 2. ]\n",
            " [4.3 3.  1.1 0.1 0. ]\n",
            " [5.  3.5 1.6 0.6 0. ]\n",
            " [7.7 2.6 6.9 2.3 2. ]\n",
            " [6.7 3.1 5.6 2.4 2. ]\n",
            " [5.4 3.4 1.5 0.4 0. ]\n",
            " [6.2 2.8 4.8 1.8 2. ]\n",
            " [6.1 2.8 4.  1.3 1. ]\n",
            " [5.2 2.7 3.9 1.4 1. ]\n",
            " [5.7 2.9 4.2 1.3 1. ]\n",
            " [6.  2.9 4.5 1.5 1. ]\n",
            " [5.4 3.9 1.7 0.4 0. ]\n",
            " [6.7 3.1 4.4 1.4 1. ]\n",
            " [6.7 3.  5.  1.7 1. ]\n",
            " [5.1 3.8 1.9 0.4 0. ]\n",
            " [4.7 3.2 1.6 0.2 0. ]\n",
            " [6.5 3.  5.5 1.8 2. ]\n",
            " [5.8 2.7 5.1 1.9 2. ]\n",
            " [5.  3.  1.6 0.2 0. ]\n",
            " [6.9 3.1 5.1 2.3 2. ]\n",
            " [6.3 3.3 4.7 1.6 1. ]\n",
            " [6.4 2.8 5.6 2.2 2. ]\n",
            " [6.6 3.  4.4 1.4 1. ]\n",
            " [7.7 3.  6.1 2.3 2. ]\n",
            " [5.5 2.4 3.8 1.1 1. ]\n",
            " [5.1 3.8 1.5 0.3 0. ]\n",
            " [4.9 2.5 4.5 1.7 2. ]\n",
            " [6.2 3.4 5.4 2.3 2. ]\n",
            " [4.9 3.  1.4 0.2 0. ]\n",
            " [5.5 2.3 4.  1.3 1. ]\n",
            " [5.2 4.1 1.5 0.1 0. ]\n",
            " [5.1 3.3 1.7 0.5 0. ]\n",
            " [5.1 2.5 3.  1.1 1. ]\n",
            " [6.4 3.1 5.5 1.8 2. ]\n",
            " [7.6 3.  6.6 2.1 2. ]\n",
            " [6.4 2.9 4.3 1.3 1. ]\n",
            " [6.1 2.9 4.7 1.4 1. ]\n",
            " [5.6 2.5 3.9 1.1 1. ]\n",
            " [5.  3.3 1.4 0.2 0. ]\n",
            " [6.6 2.9 4.6 1.3 1. ]\n",
            " [5.  3.6 1.4 0.2 0. ]\n",
            " [5.1 3.8 1.6 0.2 0. ]\n",
            " [7.2 3.  5.8 1.6 2. ]\n",
            " [6.3 2.8 5.1 1.5 2. ]\n",
            " [5.3 3.7 1.5 0.2 0. ]\n",
            " [6.1 2.6 5.6 1.4 2. ]\n",
            " [6.  2.2 5.  1.5 2. ]\n",
            " [7.2 3.2 6.  1.8 2. ]\n",
            " [5.7 3.  4.2 1.2 1. ]\n",
            " [4.6 3.6 1.  0.2 0. ]\n",
            " [4.6 3.1 1.5 0.2 0. ]\n",
            " [5.8 4.  1.2 0.2 0. ]\n",
            " [5.6 2.7 4.2 1.3 1. ]\n",
            " [5.6 2.8 4.9 2.  2. ]\n",
            " [5.1 3.4 1.5 0.2 0. ]\n",
            " [4.8 3.  1.4 0.1 0. ]\n",
            " [5.1 3.7 1.5 0.4 0. ]\n",
            " [6.4 3.2 5.3 2.3 2. ]\n",
            " [5.2 3.4 1.4 0.2 0. ]\n",
            " [6.  2.7 5.1 1.6 1. ]\n",
            " [6.7 2.5 5.8 1.8 2. ]\n",
            " [7.2 3.6 6.1 2.5 2. ]\n",
            " [5.1 3.5 1.4 0.2 0. ]\n",
            " [6.3 2.5 5.  1.9 2. ]\n",
            " [7.1 3.  5.9 2.1 2. ]\n",
            " [6.4 3.2 4.5 1.5 1. ]\n",
            " [4.8 3.4 1.9 0.2 0. ]\n",
            " [5.  3.4 1.5 0.2 0. ]\n",
            " [7.7 3.8 6.7 2.2 2. ]\n",
            " [5.4 3.  4.5 1.5 1. ]\n",
            " [4.8 3.4 1.6 0.2 0. ]\n",
            " [6.7 3.3 5.7 2.5 2. ]\n",
            " [5.1 3.5 1.4 0.3 0. ]\n",
            " [4.7 3.2 1.3 0.2 0. ]\n",
            " [6.3 2.3 4.4 1.3 1. ]\n",
            " [4.4 3.2 1.3 0.2 0. ]\n",
            " [5.  2.3 3.3 1.  1. ]\n",
            " [6.9 3.2 5.7 2.3 2. ]\n",
            " [5.9 3.  4.2 1.5 1. ]\n",
            " [5.  3.2 1.2 0.2 0. ]\n",
            " [5.6 3.  4.1 1.3 1. ]\n",
            " [5.6 3.  4.5 1.5 1. ]\n",
            " [6.1 3.  4.6 1.4 1. ]\n",
            " [6.7 3.1 4.7 1.5 1. ]\n",
            " [5.9 3.2 4.8 1.8 1. ]\n",
            " [4.9 3.1 1.5 0.1 0. ]\n",
            " [4.8 3.1 1.6 0.2 0. ]\n",
            " [6.2 2.9 4.3 1.3 1. ]\n",
            " [5.  3.5 1.3 0.3 0. ]\n",
            " [5.2 3.5 1.5 0.2 0. ]\n",
            " [5.8 2.8 5.1 2.4 2. ]\n",
            " [6.3 3.4 5.6 2.4 2. ]\n",
            " [4.8 3.  1.4 0.3 0. ]\n",
            " [7.3 2.9 6.3 1.8 2. ]\n",
            " [7.4 2.8 6.1 1.9 2. ]\n",
            " [6.5 3.2 5.1 2.  2. ]\n",
            " [6.1 3.  4.9 1.8 2. ]\n",
            " [6.  3.4 4.5 1.6 1. ]\n",
            " [5.4 3.4 1.7 0.2 0. ]\n",
            " [6.3 2.7 4.9 1.8 2. ]\n",
            " [5.8 2.7 4.1 1.  1. ]\n",
            " [6.1 2.8 4.7 1.2 1. ]\n",
            " [7.7 2.8 6.7 2.  2. ]\n",
            " [6.5 3.  5.8 2.2 2. ]\n",
            " [6.  2.2 4.  1.  1. ]\n",
            " [4.9 2.4 3.3 1.  1. ]\n",
            " [5.7 2.6 3.5 1.  1. ]\n",
            " [5.4 3.7 1.5 0.2 0. ]\n",
            " [5.7 4.4 1.5 0.4 0. ]\n",
            " [4.6 3.2 1.4 0.2 0. ]\n",
            " [5.5 4.2 1.4 0.2 0. ]\n",
            " [6.2 2.2 4.5 1.5 1. ]\n",
            " [5.8 2.7 5.1 1.9 2. ]\n",
            " [5.5 2.6 4.4 1.2 1. ]\n",
            " [4.4 2.9 1.4 0.2 0. ]\n",
            " [4.4 3.  1.3 0.2 0. ]\n",
            " [4.6 3.4 1.4 0.3 0. ]\n",
            " [6.3 3.3 6.  2.5 2. ]\n",
            " [7.9 3.8 6.4 2.  2. ]\n",
            " [6.9 3.1 5.4 2.1 2. ]\n",
            " [6.4 2.8 5.6 2.1 2. ]\n",
            " [5.  3.4 1.6 0.4 0. ]\n",
            " [5.7 2.5 5.  2.  2. ]\n",
            " [6.4 2.7 5.3 1.9 2. ]\n",
            " [5.5 2.5 4.  1.3 1. ]\n",
            " [6.7 3.  5.2 2.3 2. ]\n",
            " [4.9 3.1 1.5 0.1 0. ]\n",
            " [7.  3.2 4.7 1.4 1. ]\n",
            " [5.  2.  3.5 1.  1. ]\n",
            " [4.5 2.3 1.3 0.3 0. ]\n",
            " [6.3 2.9 5.6 1.8 2. ]\n",
            " [6.8 2.8 4.8 1.4 1. ]\n",
            " [5.8 2.6 4.  1.2 1. ]\n",
            " [6.5 3.  5.2 2.  2. ]\n",
            " [4.9 3.1 1.5 0.1 0. ]\n",
            " [5.7 2.8 4.1 1.3 1. ]\n",
            " [6.9 3.1 4.9 1.5 1. ]\n",
            " [5.6 2.9 3.6 1.3 1. ]\n",
            " [6.  3.  4.8 1.8 2. ]\n",
            " [5.7 2.8 4.5 1.3 1. ]\n",
            " [6.8 3.  5.5 2.1 2. ]\n",
            " [5.4 3.9 1.3 0.4 0. ]\n",
            " [5.9 3.  5.1 1.8 2. ]\n",
            " [5.5 3.5 1.3 0.2 0. ]\n",
            " [5.5 2.4 3.7 1.  1. ]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "train = df_array[:105]\n",
        "test = df_array[105:]\n",
        "print(len(train), len(test))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "quIyJJ2PqdzV",
        "outputId": "6a50363c-cc54-4646-b7f4-5901a00fbc80"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "105 45\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# actually using bpn\n",
        "\n",
        "bpn = BPN(train, test, 2, 0.1, 200)\n",
        "bpn.train_network()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-iJC5HfYqd9n",
        "outputId": "01397711-9742-46d5-90a6-8c9bfa0494ff"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            ">epoch=1, lrate=0.100, MSE=1.046115\n",
            ">epoch=2, lrate=0.100, MSE=0.692773\n",
            ">epoch=3, lrate=0.100, MSE=0.675856\n",
            ">epoch=4, lrate=0.100, MSE=0.675125\n",
            ">epoch=5, lrate=0.100, MSE=0.675048\n",
            ">epoch=6, lrate=0.100, MSE=0.675024\n",
            ">epoch=7, lrate=0.100, MSE=0.675007\n",
            ">epoch=8, lrate=0.100, MSE=0.674992\n",
            ">epoch=9, lrate=0.100, MSE=0.674976\n",
            ">epoch=10, lrate=0.100, MSE=0.674961\n",
            ">epoch=11, lrate=0.100, MSE=0.674946\n",
            ">epoch=12, lrate=0.100, MSE=0.674930\n",
            ">epoch=13, lrate=0.100, MSE=0.674914\n",
            ">epoch=14, lrate=0.100, MSE=0.674898\n",
            ">epoch=15, lrate=0.100, MSE=0.674880\n",
            ">epoch=16, lrate=0.100, MSE=0.674862\n",
            ">epoch=17, lrate=0.100, MSE=0.674842\n",
            ">epoch=18, lrate=0.100, MSE=0.674820\n",
            ">epoch=19, lrate=0.100, MSE=0.674797\n",
            ">epoch=20, lrate=0.100, MSE=0.674771\n",
            ">epoch=21, lrate=0.100, MSE=0.674741\n",
            ">epoch=22, lrate=0.100, MSE=0.674708\n",
            ">epoch=23, lrate=0.100, MSE=0.674670\n",
            ">epoch=24, lrate=0.100, MSE=0.674624\n",
            ">epoch=25, lrate=0.100, MSE=0.674570\n",
            ">epoch=26, lrate=0.100, MSE=0.674503\n",
            ">epoch=27, lrate=0.100, MSE=0.674418\n",
            ">epoch=28, lrate=0.100, MSE=0.674307\n",
            ">epoch=29, lrate=0.100, MSE=0.674155\n",
            ">epoch=30, lrate=0.100, MSE=0.673933\n",
            ">epoch=31, lrate=0.100, MSE=0.673581\n",
            ">epoch=32, lrate=0.100, MSE=0.672938\n",
            ">epoch=33, lrate=0.100, MSE=0.671434\n",
            ">epoch=34, lrate=0.100, MSE=0.665534\n",
            ">epoch=35, lrate=0.100, MSE=0.641822\n",
            ">epoch=36, lrate=0.100, MSE=0.609549\n",
            ">epoch=37, lrate=0.100, MSE=0.572932\n",
            ">epoch=38, lrate=0.100, MSE=0.536900\n",
            ">epoch=39, lrate=0.100, MSE=0.505223\n",
            ">epoch=40, lrate=0.100, MSE=0.478861\n",
            ">epoch=41, lrate=0.100, MSE=0.457396\n",
            ">epoch=42, lrate=0.100, MSE=0.440006\n",
            ">epoch=43, lrate=0.100, MSE=0.425871\n",
            ">epoch=44, lrate=0.100, MSE=0.414302\n",
            ">epoch=45, lrate=0.100, MSE=0.404748\n",
            ">epoch=46, lrate=0.100, MSE=0.396785\n",
            ">epoch=47, lrate=0.100, MSE=0.390087\n",
            ">epoch=48, lrate=0.100, MSE=0.384402\n",
            ">epoch=49, lrate=0.100, MSE=0.379536\n",
            ">epoch=50, lrate=0.100, MSE=0.375338\n",
            ">epoch=51, lrate=0.100, MSE=0.371690\n",
            ">epoch=52, lrate=0.100, MSE=0.368496\n",
            ">epoch=53, lrate=0.100, MSE=0.365683\n",
            ">epoch=54, lrate=0.100, MSE=0.363190\n",
            ">epoch=55, lrate=0.100, MSE=0.360969\n",
            ">epoch=56, lrate=0.100, MSE=0.358978\n",
            ">epoch=57, lrate=0.100, MSE=0.357186\n",
            ">epoch=58, lrate=0.100, MSE=0.355564\n",
            ">epoch=59, lrate=0.100, MSE=0.354090\n",
            ">epoch=60, lrate=0.100, MSE=0.352746\n",
            ">epoch=61, lrate=0.100, MSE=0.351514\n",
            ">epoch=62, lrate=0.100, MSE=0.350381\n",
            ">epoch=63, lrate=0.100, MSE=0.349335\n",
            ">epoch=64, lrate=0.100, MSE=0.348366\n",
            ">epoch=65, lrate=0.100, MSE=0.347466\n",
            ">epoch=66, lrate=0.100, MSE=0.346626\n",
            ">epoch=67, lrate=0.100, MSE=0.345839\n",
            ">epoch=68, lrate=0.100, MSE=0.345100\n",
            ">epoch=69, lrate=0.100, MSE=0.344404\n",
            ">epoch=70, lrate=0.100, MSE=0.343746\n",
            ">epoch=71, lrate=0.100, MSE=0.343122\n",
            ">epoch=72, lrate=0.100, MSE=0.342527\n",
            ">epoch=73, lrate=0.100, MSE=0.341958\n",
            ">epoch=74, lrate=0.100, MSE=0.341413\n",
            ">epoch=75, lrate=0.100, MSE=0.340887\n",
            ">epoch=76, lrate=0.100, MSE=0.340379\n",
            ">epoch=77, lrate=0.100, MSE=0.339885\n",
            ">epoch=78, lrate=0.100, MSE=0.339402\n",
            ">epoch=79, lrate=0.100, MSE=0.338930\n",
            ">epoch=80, lrate=0.100, MSE=0.338464\n",
            ">epoch=81, lrate=0.100, MSE=0.338003\n",
            ">epoch=82, lrate=0.100, MSE=0.337544\n",
            ">epoch=83, lrate=0.100, MSE=0.337087\n",
            ">epoch=84, lrate=0.100, MSE=0.336628\n",
            ">epoch=85, lrate=0.100, MSE=0.336166\n",
            ">epoch=86, lrate=0.100, MSE=0.335699\n",
            ">epoch=87, lrate=0.100, MSE=0.335227\n",
            ">epoch=88, lrate=0.100, MSE=0.334747\n",
            ">epoch=89, lrate=0.100, MSE=0.334258\n",
            ">epoch=90, lrate=0.100, MSE=0.333761\n",
            ">epoch=91, lrate=0.100, MSE=0.333253\n",
            ">epoch=92, lrate=0.100, MSE=0.332735\n",
            ">epoch=93, lrate=0.100, MSE=0.332207\n",
            ">epoch=94, lrate=0.100, MSE=0.331667\n",
            ">epoch=95, lrate=0.100, MSE=0.331117\n",
            ">epoch=96, lrate=0.100, MSE=0.330557\n",
            ">epoch=97, lrate=0.100, MSE=0.329986\n",
            ">epoch=98, lrate=0.100, MSE=0.329407\n",
            ">epoch=99, lrate=0.100, MSE=0.328818\n",
            ">epoch=100, lrate=0.100, MSE=0.328221\n",
            ">epoch=101, lrate=0.100, MSE=0.327617\n",
            ">epoch=102, lrate=0.100, MSE=0.327005\n",
            ">epoch=103, lrate=0.100, MSE=0.326387\n",
            ">epoch=104, lrate=0.100, MSE=0.325762\n",
            ">epoch=105, lrate=0.100, MSE=0.325130\n",
            ">epoch=106, lrate=0.100, MSE=0.324493\n",
            ">epoch=107, lrate=0.100, MSE=0.323851\n",
            ">epoch=108, lrate=0.100, MSE=0.323205\n",
            ">epoch=109, lrate=0.100, MSE=0.322557\n",
            ">epoch=110, lrate=0.100, MSE=0.321906\n",
            ">epoch=111, lrate=0.100, MSE=0.321256\n",
            ">epoch=112, lrate=0.100, MSE=0.320606\n",
            ">epoch=113, lrate=0.100, MSE=0.319957\n",
            ">epoch=114, lrate=0.100, MSE=0.319311\n",
            ">epoch=115, lrate=0.100, MSE=0.318668\n",
            ">epoch=116, lrate=0.100, MSE=0.318029\n",
            ">epoch=117, lrate=0.100, MSE=0.317395\n",
            ">epoch=118, lrate=0.100, MSE=0.316766\n",
            ">epoch=119, lrate=0.100, MSE=0.316143\n",
            ">epoch=120, lrate=0.100, MSE=0.315527\n",
            ">epoch=121, lrate=0.100, MSE=0.314919\n",
            ">epoch=122, lrate=0.100, MSE=0.314318\n",
            ">epoch=123, lrate=0.100, MSE=0.313727\n",
            ">epoch=124, lrate=0.100, MSE=0.313144\n",
            ">epoch=125, lrate=0.100, MSE=0.312571\n",
            ">epoch=126, lrate=0.100, MSE=0.312008\n",
            ">epoch=127, lrate=0.100, MSE=0.311455\n",
            ">epoch=128, lrate=0.100, MSE=0.310913\n",
            ">epoch=129, lrate=0.100, MSE=0.310381\n",
            ">epoch=130, lrate=0.100, MSE=0.309860\n",
            ">epoch=131, lrate=0.100, MSE=0.309349\n",
            ">epoch=132, lrate=0.100, MSE=0.308849\n",
            ">epoch=133, lrate=0.100, MSE=0.308359\n",
            ">epoch=134, lrate=0.100, MSE=0.307879\n",
            ">epoch=135, lrate=0.100, MSE=0.307410\n",
            ">epoch=136, lrate=0.100, MSE=0.306949\n",
            ">epoch=137, lrate=0.100, MSE=0.306498\n",
            ">epoch=138, lrate=0.100, MSE=0.306056\n",
            ">epoch=139, lrate=0.100, MSE=0.305623\n",
            ">epoch=140, lrate=0.100, MSE=0.305197\n",
            ">epoch=141, lrate=0.100, MSE=0.304780\n",
            ">epoch=142, lrate=0.100, MSE=0.304370\n",
            ">epoch=143, lrate=0.100, MSE=0.303967\n",
            ">epoch=144, lrate=0.100, MSE=0.303572\n",
            ">epoch=145, lrate=0.100, MSE=0.303183\n",
            ">epoch=146, lrate=0.100, MSE=0.302800\n",
            ">epoch=147, lrate=0.100, MSE=0.302423\n",
            ">epoch=148, lrate=0.100, MSE=0.302052\n",
            ">epoch=149, lrate=0.100, MSE=0.301686\n",
            ">epoch=150, lrate=0.100, MSE=0.301326\n",
            ">epoch=151, lrate=0.100, MSE=0.300970\n",
            ">epoch=152, lrate=0.100, MSE=0.300620\n",
            ">epoch=153, lrate=0.100, MSE=0.300274\n",
            ">epoch=154, lrate=0.100, MSE=0.299933\n",
            ">epoch=155, lrate=0.100, MSE=0.299595\n",
            ">epoch=156, lrate=0.100, MSE=0.299263\n",
            ">epoch=157, lrate=0.100, MSE=0.298934\n",
            ">epoch=158, lrate=0.100, MSE=0.298609\n",
            ">epoch=159, lrate=0.100, MSE=0.298287\n",
            ">epoch=160, lrate=0.100, MSE=0.297970\n",
            ">epoch=161, lrate=0.100, MSE=0.297656\n",
            ">epoch=162, lrate=0.100, MSE=0.297345\n",
            ">epoch=163, lrate=0.100, MSE=0.297038\n",
            ">epoch=164, lrate=0.100, MSE=0.296735\n",
            ">epoch=165, lrate=0.100, MSE=0.296434\n",
            ">epoch=166, lrate=0.100, MSE=0.296137\n",
            ">epoch=167, lrate=0.100, MSE=0.295843\n",
            ">epoch=168, lrate=0.100, MSE=0.295552\n",
            ">epoch=169, lrate=0.100, MSE=0.295264\n",
            ">epoch=170, lrate=0.100, MSE=0.294979\n",
            ">epoch=171, lrate=0.100, MSE=0.294697\n",
            ">epoch=172, lrate=0.100, MSE=0.294418\n",
            ">epoch=173, lrate=0.100, MSE=0.294142\n",
            ">epoch=174, lrate=0.100, MSE=0.293869\n",
            ">epoch=175, lrate=0.100, MSE=0.293598\n",
            ">epoch=176, lrate=0.100, MSE=0.293330\n",
            ">epoch=177, lrate=0.100, MSE=0.293065\n",
            ">epoch=178, lrate=0.100, MSE=0.292803\n",
            ">epoch=179, lrate=0.100, MSE=0.292544\n",
            ">epoch=180, lrate=0.100, MSE=0.292287\n",
            ">epoch=181, lrate=0.100, MSE=0.292032\n",
            ">epoch=182, lrate=0.100, MSE=0.291781\n",
            ">epoch=183, lrate=0.100, MSE=0.291532\n",
            ">epoch=184, lrate=0.100, MSE=0.291285\n",
            ">epoch=185, lrate=0.100, MSE=0.291041\n",
            ">epoch=186, lrate=0.100, MSE=0.290800\n",
            ">epoch=187, lrate=0.100, MSE=0.290561\n",
            ">epoch=188, lrate=0.100, MSE=0.290324\n",
            ">epoch=189, lrate=0.100, MSE=0.290090\n",
            ">epoch=190, lrate=0.100, MSE=0.289859\n",
            ">epoch=191, lrate=0.100, MSE=0.289629\n",
            ">epoch=192, lrate=0.100, MSE=0.289403\n",
            ">epoch=193, lrate=0.100, MSE=0.289178\n",
            ">epoch=194, lrate=0.100, MSE=0.288956\n",
            ">epoch=195, lrate=0.100, MSE=0.288736\n",
            ">epoch=196, lrate=0.100, MSE=0.288518\n",
            ">epoch=197, lrate=0.100, MSE=0.288303\n",
            ">epoch=198, lrate=0.100, MSE=0.288090\n",
            ">epoch=199, lrate=0.100, MSE=0.287879\n",
            ">epoch=200, lrate=0.100, MSE=0.287671\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "bpn.show_predictions()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "w_3-DaFPqeHH",
        "outputId": "fca90740-d3d8-4a6b-9032-faae11199694"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+ Expected=1, Got=1\n",
            "- Expected=1, Got=2\n",
            "+ Expected=2, Got=2\n",
            "+ Expected=2, Got=2\n",
            "- Expected=1, Got=2\n",
            "+ Expected=1, Got=1\n",
            "+ Expected=1, Got=1\n",
            "+ Expected=0, Got=0\n",
            "+ Expected=0, Got=0\n",
            "+ Expected=0, Got=0\n",
            "+ Expected=0, Got=0\n",
            "- Expected=1, Got=2\n",
            "+ Expected=2, Got=2\n",
            "- Expected=1, Got=2\n",
            "+ Expected=0, Got=0\n",
            "+ Expected=0, Got=0\n",
            "+ Expected=0, Got=0\n",
            "+ Expected=2, Got=2\n",
            "+ Expected=2, Got=2\n",
            "+ Expected=2, Got=2\n",
            "+ Expected=2, Got=2\n",
            "+ Expected=0, Got=0\n",
            "+ Expected=2, Got=2\n",
            "+ Expected=2, Got=2\n",
            "- Expected=1, Got=2\n",
            "+ Expected=2, Got=2\n",
            "+ Expected=0, Got=0\n",
            "+ Expected=1, Got=1\n",
            "- Expected=1, Got=2\n",
            "+ Expected=0, Got=0\n",
            "+ Expected=2, Got=2\n",
            "- Expected=1, Got=2\n",
            "+ Expected=1, Got=1\n",
            "+ Expected=2, Got=2\n",
            "+ Expected=0, Got=0\n",
            "+ Expected=1, Got=1\n",
            "- Expected=1, Got=2\n",
            "+ Expected=1, Got=1\n",
            "+ Expected=2, Got=2\n",
            "- Expected=1, Got=2\n",
            "+ Expected=2, Got=2\n",
            "+ Expected=0, Got=0\n",
            "+ Expected=2, Got=2\n",
            "+ Expected=0, Got=0\n",
            "+ Expected=1, Got=1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "bpn.get_accuracy_score()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DGCb906oqeRD",
        "outputId": "782c4929-0438-45b0-c9d8-dc038911bf02"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "80.0"
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class RBF:\n",
        "    def __init__(self, X, y, tX, ty, num_of_classes, k, std_from_clusters=True):\n",
        "        self.X = X\n",
        "        self.y = y\n",
        "\n",
        "        self.tX = tX\n",
        "        self.ty = ty\n",
        "\n",
        "        self.number_of_classes = num_of_classes\n",
        "        self.k = k\n",
        "        self.std_from_clusters = std_from_clusters\n",
        "\n",
        "    def get_distance(self, x1, x2):\n",
        "      sum = 0\n",
        "      for i in range(len(x1)):\n",
        "          sum += (x1[i] - x2[i]) ** 2\n",
        "      return np.sqrt(sum)\n",
        "\n",
        "\n",
        "    def kmeans(self, max_iters):\n",
        "      centroids = self.X[np.random.choice(range(len(self.X)), self.k, replace=False)]\n",
        "      converged = False\n",
        "      current_iter = 0\n",
        "\n",
        "      while (not converged) and (current_iter < max_iters):\n",
        "          cluster_list = [[] for i in range(len(centroids))]\n",
        "\n",
        "          for x in self.X:  # Go through each data point\n",
        "              distances_list = []\n",
        "              for c in centroids:\n",
        "                  distances_list.append(self.get_distance(c, x))\n",
        "              cluster_list[int(np.argmin(distances_list))].append(x)\n",
        "\n",
        "          cluster_list = list((filter(None, cluster_list)))\n",
        "          prev_centroids = centroids.copy()\n",
        "          centroids = []\n",
        "\n",
        "          for j in range(len(cluster_list)):\n",
        "              centroids.append(np.mean(cluster_list[j], axis=0))\n",
        "\n",
        "          pattern = np.abs(np.sum(prev_centroids) - np.sum(centroids))\n",
        "          converged = (pattern == 0)\n",
        "          current_iter += 1\n",
        "\n",
        "      return np.array(centroids), [np.std(x) for x in cluster_list]\n",
        "\n",
        "    def convert_to_one_hot(self, x, num_of_classes):\n",
        "        arr = np.zeros((len(x), num_of_classes))\n",
        "        for i in range(len(x)):\n",
        "            c = int(x[i])\n",
        "            arr[i][c] = 1\n",
        "        return arr\n",
        "\n",
        "    def rbf(self, x, c, s):\n",
        "        distance = self.get_distance(x, c)\n",
        "        return 1 / np.exp(-distance / s ** 2)\n",
        "\n",
        "    def rbf_list(self, X, centroids, std_list):\n",
        "        RBF_list = []\n",
        "        for x in X:\n",
        "            RBF_list.append([self.rbf(x, c, s) for (c, s) in zip(centroids, std_list)])\n",
        "        return np.array(RBF_list)\n",
        "\n",
        "    def fit(self):\n",
        "      self.centroids, self.std_list = self.kmeans(1000)\n",
        "\n",
        "      if not self.std_from_clusters:\n",
        "          dMax = np.max([self.get_distance(c1, c2) for c1 in self.centroids for c2 in self.centroids])\n",
        "          self.std_list = np.repeat(dMax / np.sqrt(2 * self.k), self.k)\n",
        "\n",
        "      RBF_X = self.rbf_list(self.X, self.centroids, self.std_list)\n",
        "      self.w = np.linalg.pinv(RBF_X.T @ RBF_X) @ RBF_X.T @ self.convert_to_one_hot(self.y, self.number_of_classes)\n",
        "      RBF_list_tst = self.rbf_list(self.tX, self.centroids, self.std_list)\n",
        "      \n",
        "      self.pred_ty = RBF_list_tst @ self.w\n",
        "      self.pred_ty = np.array([np.argmax(x) for x in self.pred_ty])\n",
        "    \n",
        "    def accuracy_score(self):\n",
        "      diff = self.pred_ty - self.ty\n",
        "      return (len(np.where(diff == 0)[0]) / len(diff)) * 100"
      ],
      "metadata": {
        "id": "PTDZFoZaqegk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "np.array([\n",
        "    [1, 1], \n",
        "    [2, 0]\n",
        "]) @ np.array([\n",
        "    [1, 1],\n",
        "    [2, 3]\n",
        "])"
      ],
      "metadata": {
        "id": "q39HOoYYqetA",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "376255e5-e796-4158-965c-24015b1b9eb2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[3, 4],\n",
              "       [2, 2]])"
            ]
          },
          "metadata": {},
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "x = train[:, :-1]\n",
        "y = train[:, -1].astype(np.int32)\n",
        "x_test = test[:, :-1]\n",
        "y_test = test[:, -1].astype(np.int32)"
      ],
      "metadata": {
        "id": "e4h2AVugqfVs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "rbfn = RBF(x, y, x_test, y_test, 3, 20, False)\n",
        "rbfn.fit()\n",
        "rbfn.accuracy_score()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MpuT75WDJJk3",
        "outputId": "91e3efa4-7fff-4ddf-a28a-91f0b075ae12"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "93.33333333333333"
            ]
          },
          "metadata": {},
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "for i in range(len(y_test)):\n",
        "  print(f\"{'+' if rbfn.pred_ty[i] == int(y_test[i]) else '-'} Got: { rbfn.pred_ty[i] }, Predicted: { int(y_test[i]) }\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KXcIWqmDJJy5",
        "outputId": "8b5eaf63-cf53-4ebf-cca2-37ff2465d534"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+ Got: 1, Predicted: 1\n",
            "+ Got: 1, Predicted: 1\n",
            "+ Got: 2, Predicted: 2\n",
            "+ Got: 2, Predicted: 2\n",
            "+ Got: 1, Predicted: 1\n",
            "+ Got: 1, Predicted: 1\n",
            "+ Got: 1, Predicted: 1\n",
            "+ Got: 0, Predicted: 0\n",
            "+ Got: 0, Predicted: 0\n",
            "+ Got: 0, Predicted: 0\n",
            "+ Got: 0, Predicted: 0\n",
            "+ Got: 1, Predicted: 1\n",
            "+ Got: 2, Predicted: 2\n",
            "+ Got: 1, Predicted: 1\n",
            "+ Got: 0, Predicted: 0\n",
            "+ Got: 0, Predicted: 0\n",
            "+ Got: 0, Predicted: 0\n",
            "+ Got: 2, Predicted: 2\n",
            "+ Got: 2, Predicted: 2\n",
            "+ Got: 2, Predicted: 2\n",
            "+ Got: 2, Predicted: 2\n",
            "+ Got: 0, Predicted: 0\n",
            "+ Got: 2, Predicted: 2\n",
            "+ Got: 2, Predicted: 2\n",
            "+ Got: 1, Predicted: 1\n",
            "+ Got: 2, Predicted: 2\n",
            "+ Got: 0, Predicted: 0\n",
            "+ Got: 1, Predicted: 1\n",
            "- Got: 2, Predicted: 1\n",
            "- Got: 2, Predicted: 0\n",
            "+ Got: 2, Predicted: 2\n",
            "+ Got: 1, Predicted: 1\n",
            "+ Got: 1, Predicted: 1\n",
            "+ Got: 2, Predicted: 2\n",
            "+ Got: 0, Predicted: 0\n",
            "+ Got: 1, Predicted: 1\n",
            "+ Got: 1, Predicted: 1\n",
            "+ Got: 1, Predicted: 1\n",
            "- Got: 1, Predicted: 2\n",
            "+ Got: 1, Predicted: 1\n",
            "+ Got: 2, Predicted: 2\n",
            "+ Got: 0, Predicted: 0\n",
            "+ Got: 2, Predicted: 2\n",
            "+ Got: 0, Predicted: 0\n",
            "+ Got: 1, Predicted: 1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "svm_rbf = SVC(kernel='rbf', probability=True, C=100, gamma=0.0001)\n",
        "clf = svm_rbf.fit(x, y)\n",
        "y_pred_rbf = svm_rbf.predict(x_test)\n",
        "rbf_accuracy = svm_rbf.score(x_test, y_test)\n",
        "rbf_accuracy"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PnjaD7UDJKnp",
        "outputId": "b4950671-5eb3-41f9-cf9d-f6f9cbc7b610"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.9111111111111111"
            ]
          },
          "metadata": {},
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "for i in range(len(y_test)):\n",
        "  print(f\"{'+' if y_pred_rbf[i] == int(y_test[i]) else '-'} Got: { y_pred_rbf[i] }, Predicted: { int(y_test[i]) }\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "T8RvrX4iJXa8",
        "outputId": "b64cf49b-3c2c-4695-c8ef-d484d6844a32"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+ Got: 1, Predicted: 1\n",
            "+ Got: 1, Predicted: 1\n",
            "+ Got: 2, Predicted: 2\n",
            "+ Got: 2, Predicted: 2\n",
            "+ Got: 1, Predicted: 1\n",
            "+ Got: 1, Predicted: 1\n",
            "+ Got: 1, Predicted: 1\n",
            "+ Got: 0, Predicted: 0\n",
            "+ Got: 0, Predicted: 0\n",
            "+ Got: 0, Predicted: 0\n",
            "+ Got: 0, Predicted: 0\n",
            "+ Got: 1, Predicted: 1\n",
            "+ Got: 2, Predicted: 2\n",
            "+ Got: 1, Predicted: 1\n",
            "+ Got: 0, Predicted: 0\n",
            "+ Got: 0, Predicted: 0\n",
            "+ Got: 0, Predicted: 0\n",
            "+ Got: 2, Predicted: 2\n",
            "+ Got: 2, Predicted: 2\n",
            "+ Got: 2, Predicted: 2\n",
            "+ Got: 2, Predicted: 2\n",
            "+ Got: 0, Predicted: 0\n",
            "- Got: 1, Predicted: 2\n",
            "+ Got: 2, Predicted: 2\n",
            "+ Got: 1, Predicted: 1\n",
            "+ Got: 2, Predicted: 2\n",
            "+ Got: 0, Predicted: 0\n",
            "+ Got: 1, Predicted: 1\n",
            "+ Got: 1, Predicted: 1\n",
            "+ Got: 0, Predicted: 0\n",
            "+ Got: 2, Predicted: 2\n",
            "+ Got: 1, Predicted: 1\n",
            "+ Got: 1, Predicted: 1\n",
            "+ Got: 2, Predicted: 2\n",
            "+ Got: 0, Predicted: 0\n",
            "+ Got: 1, Predicted: 1\n",
            "- Got: 2, Predicted: 1\n",
            "+ Got: 1, Predicted: 1\n",
            "- Got: 1, Predicted: 2\n",
            "+ Got: 1, Predicted: 1\n",
            "+ Got: 2, Predicted: 2\n",
            "+ Got: 0, Predicted: 0\n",
            "- Got: 1, Predicted: 2\n",
            "+ Got: 0, Predicted: 0\n",
            "+ Got: 1, Predicted: 1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"Accuracy Comparison:\")\n",
        "print(\"SVM with RBF kernel:\", rbf_accuracy * 100)\n",
        "print(\"BPN:\", bpn.get_accuracy_score())\n",
        "print(\"RBFN:\", rbfn.accuracy_score())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mv9V-QkgJXsc",
        "outputId": "0890f9b7-67c9-4baa-a83c-eebcc6b76290"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy Comparison:\n",
            "SVM with RBF kernel: 91.11111111111111\n",
            "BPN: 80.0\n",
            "RBFN: 93.33333333333333\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "x_plot = np.arange(len(y_test))\n",
        "\n",
        "plt.figure(figsize=(20,10))\n",
        "plt.subplot(221)\n",
        "plt.scatter(x_plot, y_test)\n",
        "plt.yticks([0, 1, 2])\n",
        "plt.xticks([])\n",
        "plt.title(\"True Values\")\n",
        "plt.subplot(222)\n",
        "plt.scatter(x_plot, bpn.y_pred, color=\"r\")\n",
        "plt.yticks([0, 1, 2])\n",
        "plt.xticks([])\n",
        "plt.title(\"BPN Predictions\")\n",
        "plt.subplot(223)\n",
        "plt.scatter(x_plot, rbfn.pred_ty, color=\"y\")\n",
        "plt.yticks([0, 1, 2])\n",
        "plt.xticks([])\n",
        "plt.title(\"RBFN Predictions\")\n",
        "plt.subplot(224)\n",
        "plt.scatter(x_plot, y_pred_rbf, color=\"g\")\n",
        "plt.yticks([0, 1, 2])\n",
        "plt.xticks([])\n",
        "plt.title(\"SVM with RBF Kernel Predictions\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 596
        },
        "id": "zzcm7l8uJX42",
        "outputId": "6933803e-a154-4920-e86a-bed347cc0aa1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Text(0.5, 1.0, 'SVM with RBF Kernel Predictions')"
            ]
          },
          "metadata": {},
          "execution_count": 19
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 1440x720 with 4 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    }
  ]
}